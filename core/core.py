#!/usr/bin/env python3
# -*- coding: utf-8 -*-

from concurrent.futures import process
import configparser
from core.ssh_session import Session
import logging
import sys
import time
from core.constants import EX, IG, VA
import importlib
import json
import socket
from threading import Thread
from multiprocessing import Process
from core.helper import create_new_target, generate_random, get_module, get_module_config, get_module_types, os_name, python_version, tool_config
from database.db import check_db, connect
import argparse
import os

logger = logging.getLogger(__name__)

'''
Initializes the program
'''
def load():
    # Get args
    args = get_args() # UNUSED for now

    # Read from command line
    processes = []
    while True:
        target = read_cli()
        
        if target == False:
            continue
        else:
            scan_id = generate_random(10)
            print(f"--- Scanner for {target} started (scan #{scan_id})---")

            ## Create process
            p = Process(target = scanner_start, args = (target,scan_id,))
            p.start()

'''
Function to get all modules for specific target with a certain type
Adds thread to threads array
'''
def thread_module_types(threads, config, type):
    # Append modules
    for module in get_module_types(type):
        module = module.lower()
        if config.has_section(module.capitalize()):
            threads.append(Thread(target = run_module, args = (get_module(module)(get_module_config(config, module),config["General"]),)))

    # Start & wait for finish
    for thread in threads:
        thread.start()
    
    for thread in threads:
        thread.join()

    del threads[:]
    

'''
Function to run all regression tests saved
'''
def regression_tests(threads, target):
    _path_to_regtests = os.path.join(f'{os.getcwd()}/targets/{target}/regtests')

    # Get modules
    modules = os.listdir(_path_to_regtests)

    # Get .json files
    modules = [m for m in modules if m.split('.')[-1] == "json"]

    # Create class for modules
    for module in modules:
        module_name = module.split(".")[0]

        # Read regression test file
        try:
            with open(f"{_path_to_regtests}/{module}.json") as f:
                data = json.load(f)

                # Create thread for each regression test
                for regtest, info in data:
                    threads.append(Thread(target = run_regtest, args = (module_name, regtest, info)))
        except IOError:
            pass

    # Start & wait for finish
    for thread in threads:
        thread.start()

'''
Main method for running the scanner for the target
'''
def scanner_start(target, scan_id):
    # Set logging file path
    file_handler = logging.FileHandler(os.path.join(os.getcwd(), f"targets/{target}/run_{scan_id}.log"))
    file_handler.setLevel(logging.DEBUG)
    formatter = logging.Formatter("%(asctime)s [%(levelname)s] %(message)s")
    file_handler.setFormatter(formatter)
    logger.manager.root.addHandler(file_handler)

    ## Timer start
    logger.info("Timer started for tool execution")

    ## Read config file for target
    config = configparser.ConfigParser()
    config.read(os.path.join(f'{os.getcwd()}/targets', target) + "/config.ini")

    # Get topology
    topology = {}
    with open(f'{os.getcwd()}/targets/{target}/topology.json') as f:
        topology = json.load(f)

    # Setup Jumpssh
    session = Session(topology, target)
    
    # Array to hold threads
    threads = []
    regtests_threads = []

    ### Start the regression tests brah
    ### Strong independant stage
    regression_tests(regtests_threads, target)

    ### Start IG
    thread_module_types(threads, config, IG)

    ### Start VA
    thread_module_types(threads, config, VA)

    ### Start Exploit
    thread_module_types(threads, config, EX)

    ## Wait for regression tests to finish
    ## Is running parallel with all the stages
    for thread in regtests_threads:
        thread.join()
    
    del regtests_threads[:]
    
'''
Runs a specific module
'''
def run_module(module):
    ## Run module
    module.run()

    ## Handle result
    module.get_result()

    ## Parse module result
    module.parse()

    ## Check regression
    module.check_regtests()

'''
Creates and runs a regtest
'''
def run_regtest(module_name, regtest, data):
    # Create regtest module
    cls = getattr(importlib.import_module(f'modules.{module_name.lower()}'), f"{regtest}Regression")

    # Create regression test object
    reg_obj = cls()
    reg_obj.set_data(data)

    # Run regtest
    reg_obj.run()

    # Get result
    reg_obj.get_result()

    # Parse result
    reg_obj.parse()

'''
Get CLI arguments
'''
def get_args():
    parser = argparse.ArgumentParser("python main.py")

    #parser.add_argument('-u', '--user', help="Root username", required=True)
    #parser.add_argument('-p', '--password', help="Root password", required=True)

    return parser.parse_args()
    
'''
Specify which target to run against
'''
def read_cli():
    target = input("Choose target: ")

    # Don't allow empty inputs
    if not target:
        return False 

    try:
        # Check if valid ip adress
        socket.inet_aton(target)

        # Check if target exists
        if(os.path.isdir(os.path.join(f'{os.getcwd()}/targets', target))):
            print(f"Starting scan for target: {target}")
            return target
        else:
            # Create new target
            print(f"{target} does not exists, creating new folder")

            create_new_target(target)

            print(f"Folder for {target} created, please configure it before retrying")
            return False
    except Exception:
        return False


'''
Checks that all dependencies are present
'''
def check_dependencies():
    # Check platform essentials
    if python_version() == 2:
        sys.exit("Python2 is not supported. Run the tool with Python3!")
    
    #if not "linux" in os_name():
    #    sys.exit("The tool can only be run on Linux Distributions!")

    # Check if modules are installed on tool host
    ## Also check if modules are installed on target machine
    check_db()

    # Check if DB is up & migrate new table changes
    
