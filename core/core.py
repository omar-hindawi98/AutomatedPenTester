#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import configparser
import time
from database.models import Run
from core.ssh_session import Session
import logging
import sys
from core.constants import EX, EXTERNAL, IG, INTERNAL, VA
import importlib
import json
import socket
from threading import Thread
from multiprocessing import Process
from core.helper import create_new_target, generate_random, get_module, get_module_config, get_module_types, os_name, python_version, tool_config
from database.db import check_db, db_con
import argparse
import os

from jumpssh.exception import ConnectionError

logger = logging.getLogger(__name__)

# Process specific variables
_session = None # Holds SSH Session object
_db_run = None # Run Row input for specific run
timer_start = 0 # Timer for run

'''
Initializes the program
'''
def load():
    # Get args
    args = get_args() # UNUSED for now

    # Read from command line
    processes = []
    while True:
        target = read_cli()
        
        if target == False:
            continue
        else:
            scan_id = generate_random(10)
            print(f"--- Scanner for {target} started (scan #{scan_id})---")

            ## Create process
            p = Process(target = scanner_start, args = (target,scan_id,))
            p.start()

'''
Function to get all modules for specific target with a certain type
Adds thread to threads array
'''
def thread_module_types(threads, config, type, target_type):
    global _session

    # Append modules
    for module in get_module_types(type, target_type):
        module = module.lower()
        # Check if is in config file
        if config.has_section(module.capitalize()):
            module_config = config[module.capitalize()]

            # Check if module should run
            if module_config["run"] == "True":
                ## Check type, use Nmap result to run specific tools
                cls = get_module(module)

                # Run IG independantly from others
                if type == IG:
                    threads.append(Thread(target = run_module, args = (cls(get_module_config(config, module),config["General"], _session, {}),)))
                else:
                    # Check if Nmap result exists, add to payload
                    if cls._target_type == EXTERNAL:
                        # Check which tools that can be executed, send payload with ports
                        try:
                            data = {}
                            with open(os.path.join(os.getcwd(), f"/targets/{config['General']['target']}/{module}.json"), "r") as f:
                                data = json.load(f)
                            
                            payload = {
                                "ports" : []
                            }

                            # TODO: Add services to ports here
                            # add all services
                            if "all" in cls._services:
                                for port in data["nmaprun"]["host"]["ports"].values():
                                    if port["state"]["@state"] == "open":
                                        payload["ports"].append(port["@portid"])
                            # add ports with specific services
                            else:
                                for port in data["nmaprun"]["host"]["ports"].values():
                                    if port["service"]["@name"] in cls._services and port["state"]["@state"] == "open":
                                        payload["ports"].append(port["@portid"])
                            
                            threads.append(Thread(target = run_module, args = (cls(get_module_config(config, module),config["General"], _session, payload),)))
                        except IOError:
                            logger.warn(f"Nmap result not present, skipping running module: {module.capitalize()}")
                    # If internal tool, just run
                    elif cls._target_type == INTERNAL:
                        threads.append(Thread(target = run_module, args = (cls(get_module_config(config, module),config["General"], _session, {}),)))


    # Start & wait for finish
    for thread in threads:
        thread.start()
    
    for thread in threads:
        thread.join()

    # clear from threads array
    del threads[:]
    

'''
Function to run all regression tests saved
'''
def regression_tests(threads, target):
    _path_to_regtests = os.path.join(f'{os.getcwd()}/targets/{target}/regtests')

    # Get modules
    modules = os.listdir(_path_to_regtests)

    # Get .json files
    modules = [m for m in modules if m.split('.')[-1] == "json"]

    # Create class for modules
    for module in modules:
        module_name = module.split(".")[0]

        # Read regression test file
        try:
            with open(f"{_path_to_regtests}/{module}.json") as f:
                data = json.load(f)



                # Create thread for each regression test
                for regtest, info in data:
                    threads.append(Thread(target=run_regtest, args=(module_name, regtest, info)))
        except IOError:
            pass

    # Start & wait for finish
    for thread in threads:
        thread.start()


'''
Main method for running the scanner for the target
'''
def scanner_start(target, scan_id):
    global _session, _db_run, timer_start

    # Set logging file path
    logging.basicConfig(
        filename=os.path.join(os.getcwd(), f"targets/{target}/run_{scan_id}.log"), 
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s")

    ## Timer start
    logger.info("Timer started for tool execution")
    timer_start = int(round(time.time() * 1000))

    # Create db entry for run
    _db_run = Run(
        scan_id = scan_id,
        target = target
    )

    db_session = db_con()
    if db_session:
        db_session.add(_db_run)
        db_session.commit()

    ## Read config file for target
    config = configparser.ConfigParser()
    config.read(os.path.join(f'{os.getcwd()}/targets', target) + "/config.ini")

    # Get topology
    topology = {}
    with open(f'{os.getcwd()}/targets/{target}/topology.json') as f:
        topology = json.load(f)

    # Setup Jumpssh
    _session = Session(topology, target)
    try:
        _session.connect_ssh()
    except ConnectionError as e:
        logger.error(e)
        return False

    # Create tmp directory
    try:
        tool_conf = tool_config()["General"]
        logger.info(f"Creating tempory directory at intermediate and target host: {tool_conf['rlocation']}")
        _session.run_cmd(f"mkdir {tool_conf['rlocation']}")
        _session.run_cmd_target(f"mkdir {tool_conf['rlocation']}")
    except Exception as e:
        logger.error(e)

    # Array to hold threads
    external_threads = []
    internal_threads = []
    regtests_threads = []

    ### Start the regression tests
    ### Strong independant stage
    
    logger.info(f"RUNNING REGRESSION TESTS")
    regression_tests(regtests_threads, target)

    ## Internal & External runs parallel, all times
    # Start all external tools
    logger.info(f"RUNNING EXTERNAL IG")
    thread_module_types(external_threads, config, IG, EXTERNAL)
    
    logger.info(f"RUNNING EXTERNAL VA")
    thread_module_types(external_threads, config, VA, EXTERNAL)
    
    logger.info(f"RUNNING EXTERNAL EX")
    thread_module_types(external_threads, config, EX, EXTERNAL)

    # Start all internal tools
    logger.info(f"RUNNING INTERNAL IG")
    thread_module_types(internal_threads, config, IG, INTERNAL)

    logger.info(f"RUNNING INTERNAL VA")
    thread_module_types(internal_threads, config, VA, INTERNAL)

    logger.info(f"RUNNING INTERNAL EX")
    thread_module_types(internal_threads, config, EX, INTERNAL)

    ## Wait for regression tests to finish
    ## Is running parallel with all the stages
    for thread in regtests_threads:
        thread.join()
    
    del regtests_threads[:]

    # Remove temporary directory
    try:
        tool_conf = tool_config()["General"]
        logger.info(f"Removing tempory directory at intermediate and target host: {tool_conf['rlocation']}")
        _session.run_cmd(f"rm -rf {tool_conf['rlocation']}")
        _session.run_cmd_target(f"rm -rf {tool_conf['rlocation']}")
    except Exception as e:
        logger.error(e)
    
    # Disconnect from all SSH
    _session.disconnect()

    ## Timer end
    logger.info(f"Timer ended for tool execution, took {int(round(time.time() * 1000)) - timer_start}ms to run")
    
'''
Runs a specific module
'''
def run_module(module):
    ## Init module
    module.init()

    ## Run module
    module.run()

    ## Handle result
    module.get_result()

    ## Parse module result
    module.parse()

    ## Check regression
    module.check_regtests()

'''
Creates and runs a regtest
'''
def run_regtest(module_name, regtest, data):
    # Create regtest module
    cls = getattr(importlib.import_module(f'modules.{module_name.lower()}'), f"{regtest}Regression")

    # Create regression test object
    reg_obj = cls()
    reg_obj.set_data(data)

    # Run regtest
    reg_obj.run()

    # Get result
    reg_obj.get_result()

    # Parse result
    reg_obj.parse()

'''
Get CLI arguments
'''
def get_args():
    parser = argparse.ArgumentParser("python main.py")

    #parser.add_argument('-u', '--user', help="Root username", required=True)
    #parser.add_argument('-p', '--password', help="Root password", required=True)

    return parser.parse_args()
    
'''
Specify which target to run against
'''
def read_cli():
    target = input("Choose target: ")

    # Don't allow empty inputs
    if not target:
        return False 

    try:
        # Check if valid ip adress
        socket.inet_aton(target)

        # Check if target exists
        if(os.path.isdir(os.path.join(f'{os.getcwd()}/targets', target))):
            print(f"Starting scan for target: {target}")
            return target
        else:
            # Create new target
            print(f"{target} does not exists, creating new folder")

            create_new_target(target)

            print(f"Folder for {target} created, please configure it before retrying")
            return False
    except Exception:
        return False


'''
Checks that all dependencies are present
'''
def check_dependencies():
    # Check platform essentials
    if python_version() == 2:
        sys.exit("Python2 is not supported. Run the tool with Python3!")
    
    if not "linux" in os_name():
        sys.exit("The tool can only be run on Linux Distributions!")

    # Check if modules are installed on tool host
    ## Also check if modules are installed on target machine
    

    # Check if DB is up & migrate new table changes
    check_db()